# test_installation.py
"""
Test script for Legal Assistant Phase 1 installation
Ø§Ø³Ú©Ø±ÛŒÙ¾Øª ØªØ³Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ÙØ§Ø² Û± Ø¯Ø³ØªÛŒØ§Ø± Ø­Ù‚ÙˆÙ‚ÛŒ
"""

import sys
from pathlib import Path
import json
import traceback

# Add project root to Python path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_imports():
    """Test if all required modules can be imported"""
    print("ğŸ” Ø¨Ø±Ø±Ø³ÛŒ import modules...")
    
    try:
        from src.core.config import validate_config, get_config
        print("âœ… src.core.config")
        
        from src.core.models import LegalDocument, LegalArticle, TextChunk
        print("âœ… src.core.models")
        
        from src.utils.text_utils import PersianTextProcessor
        print("âœ… src.utils.text_utils")
        
        from src.data_processing.document_splitter import DocumentSplitter
        print("âœ… src.data_processing.document_splitter")
        
        from src.data_processing.document_parser import LegalDocumentParser
        print("âœ… src.data_processing.document_parser")
        
        from src.data_processing.text_processor import AdvancedTextProcessor
        print("âœ… src.data_processing.text_processor")
        
        from src.data_processing.chunker import IntelligentChunker
        print("âœ… src.data_processing.chunker")
        
        from src.data_processing.metadata_generator import MetadataGenerator
        print("âœ… src.data_processing.metadata_generator")
        
        return True
    
    except ImportError as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± import: {str(e)}")
        print("\nğŸ”§ Ø±Ø§Ù‡â€ŒØ­Ù„â€ŒÙ‡Ø§ÛŒ Ø§Ø­ØªÙ…Ø§Ù„ÛŒ:")
        print("   1. Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯ Ú©Ù‡ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯")
        print("   2. Ø§Ø¬Ø±Ø§ÛŒ: pip install python-docx pydantic hazm tqdm")
        print("   3. Ø¨Ø±Ø±Ø³ÛŒ syntax ÙØ§ÛŒÙ„â€ŒÙ‡Ø§")
        return False

def test_python_packages():
    """Test if required Python packages are installed"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ Python...")
    
    required_packages = [
        ('docx', 'python-docx'),
        ('pydantic', 'pydantic'),
        ('hazm', 'hazm'),
        ('tqdm', 'tqdm'),
        ('re', 'regex (built-in)'),
        ('json', 'json (built-in)'),
        ('pathlib', 'pathlib (built-in)'),
        ('datetime', 'datetime (built-in)')
    ]
    
    missing_packages = []
    
    for package, install_name in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package} - Ù†ØµØ¨ Ú©Ù†ÛŒØ¯: pip install {install_name}")
            missing_packages.append(install_name)
    
    if missing_packages:
        print(f"\nğŸ”§ Ø¯Ø³ØªÙˆØ± Ù†ØµØ¨ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ Ù…ÙÙ‚ÙˆØ¯:")
        print(f"pip install {' '.join([p for p in missing_packages if 'built-in' not in p])}")
        return False
    
    return True

def test_persian_processing():
    """Test Persian text processing capabilities"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ...")
    
    try:
        from src.utils.text_utils import PersianTextProcessor
        
        processor = PersianTextProcessor()
        
        # Test text cleaning
        test_text = "   Ù‚Ø§Ù†ÙˆÙ†    Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù†ØªØ¸Ø§Ù…ÛŒ Ù‡ÛŒØ¦Øª Ø¹Ù„Ù…ÛŒ   ( Ù…ØµÙˆØ¨ 22/12/1364 )   "
        cleaned = processor.clean_text(test_text)
        print(f"âœ… ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù…ØªÙ†: '{test_text[:30]}...' â†’ '{cleaned[:30]}...'")
        
        # Test keyword extraction
        sample_content = "Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø§Ø¹Ø¶Ø§ÛŒ Ù‡ÛŒØ¦Øª Ø¹Ù„Ù…ÛŒ Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡â€ŒÙ‡Ø§ Ù…ÙˆØ¸Ù Ø¨Ù‡ Ø±Ø¹Ø§ÛŒØª Ù…Ù‚Ø±Ø±Ø§Øª Ø§Ù†ØªØ¸Ø§Ù…ÛŒ Ù‡Ø³ØªÙ†Ø¯."
        keywords = processor.extract_keywords(sample_content, max_keywords=5)
        print(f"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡: {keywords}")
        
        # Test Persian validation
        is_valid = processor.is_valid_persian_text(sample_content)
        print(f"âœ… Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ ÙØ§Ø±Ø³ÛŒ: {is_valid}")
        
        # Test normalization
        test_chars = "Ùƒ ÙŠ Ø¡"
        normalized = processor.normalize_persian_text(test_chars)
        print(f"âœ… Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ú©Ø§Ø±Ø§Ú©ØªØ±: '{test_chars}' â†’ '{normalized}'")
        
        return True
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø±Ø³ÛŒ: {str(e)}")
        return False

def test_configuration():
    """Test system configuration"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…...")
    
    try:
        from src.core.config import validate_config, get_config
        
        # Test config validation
        if validate_config():
            print("âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ… Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª")
        else:
            print("âš ï¸ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ… Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø±Ø¯")
        
        # Test config loading
        config = get_config()
        print(f"âœ… Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {len(config)} Ø¨Ø®Ø´")
        
        # Test specific configs
        doc_config = config.get('document', {})
        if doc_config:
            print(f"âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ù†Ø¯: {len(doc_config)} Ù¾Ø§Ø±Ø§Ù…ØªØ±")
        
        return True
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {str(e)}")
        return False

def test_models():
    """Test Pydantic models"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡...")
    
    try:
        from src.core.models import LegalDocument, LegalArticle, TextChunk, DocumentType, ApprovalAuthority
        
        # Test LegalArticle creation
        article = LegalArticle(
            number="Ù…Ø§Ø¯Ù‡ Û±",
            title="ØªØ¹Ø§Ø±ÛŒÙ",
            content="Ø¯Ø± Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ú©Ù„Ù…Ø§Øª Ùˆ Ø¹Ø¨Ø§Ø±Ø§Øª Ø²ÛŒØ± Ø¯Ø± Ù…Ø¹Ø§Ù†ÛŒ Ù…Ø´Ø±ÙˆØ­ Ù…Ù‚Ø§Ø¨Ù„ Ø¢Ù†Ù‡Ø§ Ø¨Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒØ±ÙˆÙ†Ø¯."
        )
        print(f"âœ… Ù…Ø¯Ù„ LegalArticle: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª = {article.word_count}")
        
        # Test LegalDocument creation
        document = LegalDocument(
            id="test_001",
            title="Ù‚Ø§Ù†ÙˆÙ† Ù†Ù…ÙˆÙ†Ù‡",
            approval_date="01/01/1400",
            approval_authority="Ù…Ø¬Ù„Ø³ Ø´ÙˆØ±Ø§ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ",
            document_type="Ù‚Ø§Ù†ÙˆÙ†",
            standalone_articles=[article]
        )
        print(f"âœ… Ù…Ø¯Ù„ LegalDocument: {document.total_articles} Ù…Ø§Ø¯Ù‡")
        
        # Test JSON serialization
        doc_json = document.json(ensure_ascii=False)
        json_obj = json.loads(doc_json)
        print(f"âœ… Ø³Ø±ÛŒØ§Ù„Ø§ÛŒØ²ÛŒØ´Ù† JSON: {len(doc_json)} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        # Test TextChunk
        chunk = TextChunk(
            id="test_chunk_001",
            document_id="test_001",
            content="Ø§ÛŒÙ† ÛŒÚ© chunk ØªØ³Øª Ø§Ø³Øª.",
            chunk_type="article",
            position=0
        )
        print(f"âœ… Ù…Ø¯Ù„ TextChunk: {chunk.character_count} Ú©Ø§Ø±Ø§Ú©ØªØ±")
        
        return True
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§: {str(e)}")
        traceback.print_exc()
        return False

def test_file_structure():
    """Test project file structure"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø§Ø®ØªØ§Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§...")
    
    required_dirs = [
        "data/raw",
        "data/processed", 
        "data/sample",
        "src/core",
        "src/data_processing",
        "src/utils",
        "scripts"
    ]
    
    required_files = [
        "src/__init__.py",
        "src/core/__init__.py",
        "src/core/config.py",
        "src/core/models.py",
        "src/utils/__init__.py",
        "src/utils/text_utils.py",
        "src/data_processing/__init__.py",
        "src/data_processing/document_splitter.py",
        "src/data_processing/document_parser.py",
        "src/data_processing/text_processor.py",
        "src/data_processing/chunker.py",
        "src/data_processing/metadata_generator.py",
        "scripts/process_documents.py"
    ]
    
    all_good = True
    
    # Check directories
    print("ğŸ“ Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§:")
    for dir_path in required_dirs:
        if Path(dir_path).exists():
            print(f"   âœ… {dir_path}")
        else:
            print(f"   âŒ Ù¾ÙˆØ´Ù‡ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {dir_path}")
            all_good = False
    
    # Check files
    print("\nğŸ“„ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§:")
    for file_path in required_files:
        if Path(file_path).exists():
            file_size = Path(file_path).stat().st_size
            print(f"   âœ… {file_path} ({file_size} bytes)")
        else:
            print(f"   âŒ ÙØ§ÛŒÙ„ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
            all_good = False
    
    return all_good

def test_sample_processing():
    """Test sample document processing"""
    print("\nğŸ” ØªØ³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù…ÙˆÙ†Ù‡...")
    
    try:
        from src.data_processing.document_splitter import DocumentSplitter
        from src.data_processing.text_processor import AdvancedTextProcessor
        from src.utils.text_utils import PersianTextProcessor
        
        # Test document splitter initialization
        splitter = DocumentSplitter()
        print("âœ… DocumentSplitter Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª")
        
        # Test text processor
        text_processor = AdvancedTextProcessor()
        
        # Test sample text processing
        sample_law = {
            'id': 'test_001',
            'title': 'Ù‚Ø§Ù†ÙˆÙ† Ù†Ù…ÙˆÙ†Ù‡ ØªØ³Øª',
            'raw_content': 'Ù…Ø§Ø¯Ù‡ Û± - Ø§ÛŒÙ† Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´.',
            'approval_date': '01/01/1400',
            'approval_authority': 'Ù…Ø¬Ù„Ø³ Ø´ÙˆØ±Ø§ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ'
        }
        
        processed_law = text_processor.process_document_from_dict(sample_law.copy())
        print("âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ù†Ù…ÙˆÙ†Ù‡ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ²")
        
        # Test Persian processor
        persian_processor = PersianTextProcessor()
        test_text = "Ø§ÛŒÙ† ÛŒÚ© Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø§Ø³Øª."
        cleaned = persian_processor.clean_text(test_text)
        print(f"âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø±Ø³ÛŒ: '{test_text}' â†’ '{cleaned}'")
        
        return True
    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ù¾Ø±Ø¯Ø§Ø²Ø´: {str(e)}")
        traceback.print_exc()
        return False

def check_input_file():
    """Check if input file exists"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ...")
    
    input_file = Path("data/raw/Part2_Legals.docx")
    
    if input_file.exists():
        file_size = input_file.stat().st_size / (1024 * 1024)  # MB
        print(f"âœ… ÙØ§ÛŒÙ„ ÙˆØ±ÙˆØ¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª: {file_size:.1f} MB")
        
        # Test if file is readable
        try:
            from docx import Document
            doc = Document(str(input_file))
            para_count = len(doc.paragraphs)
            print(f"âœ… ÙØ§ÛŒÙ„ Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ø§Ø³Øª: {para_count} Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§Ù")
            return True
        except Exception as e:
            print(f"âš ï¸ ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª Ø§Ù…Ø§ Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ÛŒØ³Øª: {str(e)}")
            return False
    else:
        print("âš ï¸ ÙØ§ÛŒÙ„ Part2_Legals.docx Ø¯Ø± data/raw/ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        print("   Ù„Ø·ÙØ§Ù‹ ÙØ§ÛŒÙ„ Ø±Ø§ Ø¯Ø± Ù…Ø³ÛŒØ± ØµØ­ÛŒØ­ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯")
        print("   Ø±Ø§Ù‡Ù†Ù…Ø§: Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ø§ Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ù†ÛŒØ¯")
        return False

def test_write_permissions():
    """Test write permissions in project directories"""
    print("\nğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬ÙˆØ²Ù‡Ø§ÛŒ Ù†ÙˆØ´ØªÙ†...")
    
    test_dirs = ["data/processed", "data/sample"]
    all_good = True
    
    for test_dir in test_dirs:
        try:
            Path(test_dir).mkdir(exist_ok=True)
            test_file = Path(test_dir) / "write_test.tmp"
            test_file.write_text("test")
            test_file.unlink()
            print(f"âœ… Ù…Ø¬ÙˆØ² Ù†ÙˆØ´ØªÙ† Ø¯Ø± {test_dir}")
        except Exception as e:
            print(f"âŒ Ù…Ø´Ú©Ù„ Ù…Ø¬ÙˆØ² Ù†ÙˆØ´ØªÙ† Ø¯Ø± {test_dir}: {str(e)}")
            all_good = False
    
    return all_good

def generate_test_report():
    """Generate a comprehensive test report"""
    print("\n" + "="*60)
    print("ğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ ØªØ³Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ")
    print("="*60)
    
    tests = [
        ("Python Packages", test_python_packages),
        ("Import Modules", test_imports),
        ("Persian Processing", test_persian_processing),
        ("Configuration", test_configuration),
        ("Data Models", test_models),
        ("File Structure", test_file_structure),
        ("Sample Processing", test_sample_processing),
        ("Write Permissions", test_write_permissions),
        ("Input File", check_input_file)
    ]
    
    results = {}
    total_tests = len(tests)
    passed_tests = 0
    
    for test_name, test_func in tests:
        print(f"\n--- {test_name} ---")
        try:
            result = test_func()
            results[test_name] = "PASS" if result else "FAIL"
            if result:
                passed_tests += 1
        except Exception as e:
            results[test_name] = f"ERROR: {str(e)}"
            print(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± {test_name}: {str(e)}")
    
    # Print summary
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
    print(f"   âœ… Ù…ÙˆÙÙ‚: {passed_tests}/{total_tests}")
    print(f"   âŒ Ù†Ø§Ù…ÙˆÙÙ‚: {total_tests - passed_tests}/{total_tests}")
    print(f"   ğŸ“ˆ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: {(passed_tests/total_tests)*100:.1f}%")
    
    # Detailed results
    print(f"\nğŸ“‹ Ù†ØªØ§ÛŒØ¬ ØªÙØµÛŒÙ„ÛŒ:")
    for test_name, result in results.items():
        status_icon = "âœ…" if result == "PASS" else "âŒ"
        print(f"   {status_icon} {test_name}: {result}")
    
    # Recommendations
    print(f"\nğŸ’¡ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§:")
    if passed_tests == total_tests:
        print("   ğŸ‰ Ù‡Ù…Ù‡ ØªØ³Øªâ€ŒÙ‡Ø§ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ²! Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø¬Ø±Ø§ÛŒ ÙØ§Ø² Û± Ù‡Ø³ØªÛŒØ¯.")
        print("   â–¶ï¸  Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´:")
        print("       python scripts/process_documents.py data/raw/Part2_Legals.docx")
        print("   â–¶ï¸  Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§:")
        print("       python demo_phase1.py")
    else:
        failed_tests = [name for name, result in results.items() if result != "PASS"]
        
        if "Python Packages" in failed_tests:
            print("   ğŸ“¦ Ø§Ø¨ØªØ¯Ø§ Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø±Ø§ Ù†ØµØ¨ Ú©Ù†ÛŒØ¯:")
            print("       pip install python-docx pydantic hazm tqdm regex")
        
        if "File Structure" in failed_tests:
            print("   ğŸ“‚ Ø³Ø§Ø®ØªØ§Ø± Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ú©Ø§Ù…Ù„ Ú©Ù†ÛŒØ¯:")
            print("       mkdir -p data/{raw,processed,sample} src/{core,data_processing,utils} scripts")
        
        if "Input File" in failed_tests:
            print("   ğŸ“ ÙØ§ÛŒÙ„ Part2_Legals.docx Ø±Ø§ Ø¯Ø± data/raw/ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯")
        
        if "Import Modules" in failed_tests:
            print("   ğŸ”§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©Ø¯ Ø±Ø§ Ø§Ø² artifacts Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯")
        
        if "Write Permissions" in failed_tests:
            print("   ğŸ” Ù…Ø¬ÙˆØ²Ù‡Ø§ÛŒ Ù†ÙˆØ´ØªÙ† Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯:")
            print("       chmod 755 data/")
    
    return results

def main():
    """Main function"""
    print("ğŸš€ Ø´Ø±ÙˆØ¹ ØªØ³Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒØ§Ø± Ø­Ù‚ÙˆÙ‚ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ - ÙØ§Ø² Û±")
    print("="*60)
    print(f"ğŸ“ Ù…Ø³ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡: {Path.cwd()}")
    print(f"ğŸ Ù†Ø³Ø®Ù‡ Python: {sys.version}")
    
    # Generate comprehensive test report
    results = generate_test_report()
    
    # Save test results
    try:
        test_results_file = Path("test_results.json")
        with open(test_results_file, 'w', encoding='utf-8') as f:
            json.dump({
                'timestamp': str(datetime.now().isoformat() if 'datetime' in globals() else 'unknown'),
                'python_version': sys.version,
                'project_path': str(Path.cwd()),
                'results': results,
                'total_tests': len(results),
                'passed_tests': sum(1 for r in results.values() if r == "PASS"),
                'success_rate': (sum(1 for r in results.values() if r == "PASS") / len(results)) * 100
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ Ù†ØªØ§ÛŒØ¬ ØªØ³Øª Ø¯Ø± ÙØ§ÛŒÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {test_results_file}")
    
    except Exception as e:
        print(f"\nâš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù†ØªØ§ÛŒØ¬: {str(e)}")
    
    print(f"\n{'='*60}")
    print("âœ¨ ØªØ³Øª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯!")

if __name__ == "__main__":
    try:
        from datetime import datetime
        main()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ØªØ³Øª ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
    except Exception as e:
        print(f"\nğŸ’¥ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {str(e)}")
        traceback.print_exc()